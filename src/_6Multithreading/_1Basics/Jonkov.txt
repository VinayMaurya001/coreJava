Java Concurrency and Multithreading
Java Concurrency is a term that covers multithreading, concurrency and parallelism on the Java platform. That includes the Java concurrency tools, problems and solutions. 

AKA: also known as

Multithreading and Concurrency in Java
Java was one of the first languages to make multithreading easily available to developers. Java had multithreading capabilities from the very beginning. 

Java Concurrency in 2015 and Forward
A lot has happened in the world of concurrent architecture and design since the first Java concurrency books were written, and even since the Java 5 concurrency utilities were released.

New, asynchronous "shared-nothing" platforms and APIs like Vert.x and Play / Akka and Qbit have emerged. These platforms use a different concurrency model than the standard Java / JEE concurrency model of threading, shared memory and locking. New non-blocking concurrency algorithms have been published, and new non-blocking tools like the LMax Disrupter have been added to our toolkits. New functional programming parallelism has been introduced with the Fork and Join framework in Java 7, and the collection streams API in Java 8.

With all these new developments it is about time that I updated this Java Concurrency tutorial. Therefore, this tutorial is once again work in progress. New tutorials will be published whenever time is available to write them.


Java Concurrency Study Guide
General concurrency and multithreading theory:

Multithreading Benefits
Multithreading Costs
Concurrency Models
Same-threading
Concurrency vs. Parallelism
The basics of Java concurrency:

Creating and Starting Java Threads
Race Conditions and Critical Sections
Thread Safety and Shared Resources
Thread Safety and Immutability
Java Memory Model
Java Synchronized Blocks
Java Volatile Keyword
Java ThreadLocal
Java Thread Signaling
Typical problems in Java concurrency:

Deadlock
Deadlock Prevention
Starvation and Fairness
Nested Monitor Lockout
Slipped Conditions
Java concurrency constructs that help against the issues above:

Locks in Java
Read / Write Locks in Java
Reentrance Lockout
Semaphores
Blocking Queues
Thread Pools
Compare and Swap
Further topics:

Anatomy of a Synchronizer
Non-blocking Algorithms
Amdahl's Law
References



Multithreading Benefits
	Better resource utilization.
	Simpler program design in some situations.
	More responsive programs.

Multithreading Costs
	More complex design
	Context Switching Overhead
	Increased Resource Consumption


Concurrency Models and Distributed System Similarities
Concurrency Models:
1)Parallel Workers
	Parallel Workers Advantages
	Parallel Workers Disadvantages
		Shared State Can Get Complex
			non-blocking concurrency algorithms
			Persistent data structures 
		Stateless Workers
		Job Ordering is Nondeterministic
2)Assembly Line(or reactive systems, or event driven systems)
		Vert.x
		Akka
		Node.JS (JavaScript)
	Assembly Line Advantages
		No Shared State
		Stateful Workers
		Better Hardware Conformity
		Job Ordering is Possible
	Assembly Line Disadvantages
3)Functional Parallelism
Which Concurrency Model is Best?
4) Same-threading
	Why Single-threaded Systems?
	Same-threading, Single-threading Scaled Out
		One Thread Per CPU
	No Shared State
	Load Distribution
		Single-threaded Microservices
		Services With Sharded Data
	Thread Communication
	Simpler Concurrency Model
	Illustrations




Concurrency vs. Parallelism

Java Threads
Creating and Starting Threads
	Thread Subclass	
	Runnable Interface Implementation
		Java Class Implements Runnable
		Anonymous Implementation of Runnable
		Java Lambda Implementation of Runnable
		Starting a Thread With a Runnable
Subclass or Runnable?
	There are no rules about which of the two methods that is the best. Both methods works. Personally though, I prefer implementing Runnable, and handing an instance of the implementation to a Thread instance. When having the Runnable's executed by a thread pool it is easy to queue up the Runnable instances until a thread from the pool is idle. This is a little harder to do with Thread subclasses.
	Sometimes you may have to implement Runnable as well as subclass Thread. For instance, if creating a subclass of Thread that can execute more than one Runnable. This is typically the case when implementing a thread pool.
Common Pitfall: Calling run() Instead of start()
Thread Names
Thread.currentThread()
Java Thread Example
Pause a Thread
Stop a Thread
	public class MyRunnable implements Runnable {

    private boolean doStop = false;

    public synchronized void doStop() {
        this.doStop = true;
    }

    private synchronized boolean keepRunning() {
        return this.doStop == false;
    }

    @Override
    public void run() {
        while(keepRunning()) {
            // keep doing what this thread should do.
            System.out.println("Running");

            try {
                Thread.sleep(3L * 1000L);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

        }
    }
}
Please keep in mind that if your Runnable implementation needs more than just the run() method (e.g. a stop() or pause() method too), then you can no longer create your Runnable implementation with a Java lambda expression. A Java lambda can only implement a single method. Instead you must use a custom class, or a custom interface that extends Runnable which has the extra methods, and which is implemented by an anonymous class.



Race Conditions and Critical Sections
A race condition is a special condition that may occur inside a critical section. A critical section is a section of code that is executed by multiple threads and where the sequence of execution for the threads makes a difference in the result of the concurrent execution of the critical section.
When the result of multiple threads executing a critical section may differ depending on the sequence in which the threads execute, the critical section is said to contain a race condition. The term race condition stems from the metaphor that the threads are racing through the critical section, and that the result of that race impacts the result of executing the critical section.

Critical Sections
Running more than one thread inside the same application does not by itself cause problems. The problems arise when multiple threads access the same resources. For instance the same memory (variables, arrays, or objects), systems (databases, web services etc.) or files.
In fact, problems only arise if one or more of the threads write to these resources. It is safe to let multiple threads read the same resources, as long as the resources do not change.
http://tutorials.jenkov.com/java-concurrency/race-conditions-and-critical-sections.html

Race Conditions in Critical Sections

Preventing Race Conditions
To prevent race conditions from occurring you must make sure that the critical section is executed as an atomic instruction. That means that once a single thread is executing it, no other threads can execute it until the first thread has left the critical section.
Race conditions can be avoided by proper thread synchronization in critical sections. Thread synchronization can be achieved using a synchronized block of Java code. 
Thread synchronization can also be achieved using other synchronization constructs like locks or atomic variables like java.util.concurrent.atomic.AtomicInteger.

Critical Section Throughput
public class TwoSums {
    
    private int sum1 = 0;
    private int sum2 = 0;

    private Integer sum1Lock = new Integer(1);
    private Integer sum2Lock = new Integer(2);

    public void add(int val1, int val2){
        synchronized(this.sum1Lock){
            this.sum1 += val1;   
        }
        synchronized(this.sum2Lock){
            this.sum2 += val2;
        }
    }
}




Thread Safety and Shared Resources
Local Variables
Local Object References
Object Member Variables
The Thread Control Escape Rule

Code that is safe to call by multiple threads simultaneously is called thread safe. 
If a piece of code is thread safe, then it contains no race conditions. Race condition only occur when multiple threads update shared resources. 

Local Variables
All local primitive variables are thread safe. 

Local Object References
Object Member Variables
The Thread Control Escape Rule
	If a resource is created, used and disposed within the control of the same thread,
	and never escapes the control of this thread, the use of that resource is thread safe.

Resources can be any shared resource like an object, array, file, database connection, socket etc. In Java you do not always explicitly dispose objects, so "disposed" means losing or null'ing the reference to the object.

This could also happen with threads operating on files or other shared resources. Therefore it is important to distinguish between whether an object controlled by a thread is the resource, or if it merely references the resource (like a database connection does).


Thread Safety and Immutability
We can make sure that objects shared between threads are never updated by any of the threads by making the shared objects immutable, and thereby thread safe.

The Reference is not Thread Safe!
The ImmutableValue class is thread safe, but the use of it is not. 






Java Memory Model
The Internal Java Memory Model
	Thread Stack
	Heap
Hardware Memory Architecture
	CPU
	CPU Registers
	CPU cache memory
	RAM-main memory

Bridging The Gap Between The Java Memory Model And The Hardware Memory Architecture
	Visibility of Shared Objects
		The volatile keyword can make sure that a given variable is read directly from main memory, and always written back to main memory when updated.
	Race Conditions
		A synchronized block guarantees that only one thread can enter a given critical section of the code at any given time. Synchronized blocks also guarantee that all variables accessed inside the synchronized block will be read in from main memory, and when the thread exits the synchronized block, all updated variables will be flushed back to main memory again, regardless of whether the variable is declared volatile or not.


Java Synchronized Blocks
The Java synchronized Keyword
Synchronized Instance Methods
Synchronized Static Methods
Synchronized Blocks in Instance Methods
Synchronized Blocks in Static Methods
Java Synchronized Example
Java Concurrency Utilities


Java Volatile Keyword
Variable Visibility Problems
The Java volatile Visibility Guarantee
	Full volatile Visibility Guarantee
Instruction Reordering Challenges
The Java volatile Happens-Before Guarantee
volatile is Not Always Enough
When is volatile Enough?
Performance Considerations of volatile

The Java volatile keyword is used to mark a Java variable as "being stored in main memory". More precisely that means, that every read of a volatile variable will be read from the computer's main memory, and not from the CPU cache, and that every write to a volatile variable will be written to main memory, and not just to the CPU cache.



Java ThreadLocal
Creating a ThreadLocal
Accessing a ThreadLocal
Generic ThreadLocal
Initial ThreadLocal Value
Full ThreadLocal Example
InheritableThreadLocal


Thread Signaling
Signaling via Shared Objects
Busy Wait
wait(), notify() and notifyAll()
Missed Signals
Spurious Wakeups
Multiple Threads Waiting for the Same Signals
Don't call wait() on constant String's or global objects


Deadlock
Thread Deadlock
Database Deadlocks

Deadlock Prevention
Lock Ordering
Lock Timeout
Deadlock Detection

Starvation and Fairness
Causes of Starvation in Java
Threads with high priority swallow all CPU time from threads with lower priority
Threads are blocked indefinitely waiting to enter a synchronized block
Threads waiting on an object (called wait() on it) remain waiting indefinitely
Implementing Fairness in Java
Using Locks Instead of Synchronized Blocks
A Fair Lock
A Note on Performance


Nested Monitor Lockout
How Nested Monitor Lockout Occurs
A More Realistic Example
Nested Monitor Lockout vs. Deadlock

Slipped Conditions
What is Slipped Conditions?
A More Realistic Example
Removing the Slipped Conditions Problem


Locks in Java
A Simple Lock
Lock Reentrance
Lock Fairness
Calling unlock() From a finally-clause



