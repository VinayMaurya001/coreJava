java.util.stream.Stream Interface


Stream<T> filter(Predicate<? super T> predicate);
	The filter() method allows us to pick stream of elements which satisfy a predicate.
	Stream<String> stream = list.stream().filter(element -> element.contains("d"));

<R> Stream<R> map(Function<? super T, ? extends R> mapper);
		It is used to transform one object into other by applying a function
	IntStream mapToInt(ToIntFunction<? super T> mapper);
	LongStream mapToLong(ToLongFunction<? super T> mapper);
	DoubleStream mapToDouble(ToDoubleFunction<? super T> mapper);

<R> Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper);
		flatMap() is used to flatten a stream of collections to a stream of Objects(String/Integer)
		Stream<List<List<String>>>->flatMap()->Stream<String> 
	IntStream flatMapToInt(Function<? super T, ? extends IntStream> mapper);
	LongStream flatMapToLong(Function<? super T, ? extends LongStream> mapper);
	DoubleStream flatMapToDouble(Function<? super T, ? extends DoubleStream> mapper);
	
	Transform each element to a stream of its constituent elements and flatten all the streams into a single stream
	
	List<String> uris = new ArrayList<>();
	uris.add("C:\\My.txt");
	Stream<String> stringStream =uris.stream();
	Stream<Path> pathStream =stringStream.map(uri -> Paths.get(uri));
	So, the code above converts Stream<String> to the Stream<Path> by applying a specific lambda expression to every element of the initial Stream.
	If you have a stream where every element contains its own sequence of elements and 
		you want to create a stream of these inner elements, you should use the flatMap() method:
		List<Detail> details = new ArrayList<>();
		details.add(new Detail());
		Stream<String> stream= details.stream().flatMap(detail -> detail.getParts().stream());
		In this example, we have a list of elements of type Detail. 
		The Detail class contains a field PARTS, which is a List<String>. 
		With the help of the flatMap() method every element from field PARTS will be extracted and added to the new resulting stream. 
		After that, the initial Stream<Detail> will be lost.
		
	List<String> list = Arrays.asList("a", "b", "c");
		List list2 = list.stream().map(str -> str.toUpperCase()).collect(Collectors.toList());
		System.out.println(list2);
		List<List<String>> list21 = new ArrayList<>();
		list21.add(Arrays.asList("a", "b", "c"));
		list21.add(Arrays.asList("x", "y", "z"));
		List<String> list32 = list21.stream().flatMap(list31 -> list31.stream().map(str -> str.toUpperCase())).collect(Collectors.toList());
		System.out.println(list32);// A,B,C,X,Y,Z
		
	Map() & flatMap() both can be applied to a Stream<T> & both return a Stream<R>. 
		The difference is that the map operation produces one output value for each input value, 
			where as the flatMap() opration produces an arbitrary number(0 or more) values for each input.
		
Stream<T> distinct();		
		List<A> distinct = list.stream().distinct().collect(Collectors.toList());
		Here  class  "A" must have implemented equals() & hashcode().
		
Stream<T> sorted();
		sorted()- default natural sorting order 
Stream<T> sorted(Comparator<? super T> comparator);
		sorted(Comparator c)-customized sorting order.
		Processing by sorted()method 
		List<String> l3=l.stream().sorted().collect(Collectors.toList()); 
		List<String> l4=l.stream().sorted((s1,s2) -> -s1.compareTo(s2)).collect(Collectors.toList()); 
		List<String> l5=l.stream().sorted(Comparator.comparing(str -> str.length())).collect(Collectors.toList());
					eList.stream().sorted(Comparator.comparing(emp -> emp.name)).collect(Collectors.toList());
		Comparator<EmployeeDetails2> empNameComparator = Comparator.comparing(EmployeeDetails2::getName)
				.thenComparing((emp) -> -emp.salary);
				Collections.sort(eList, empNameComparator);
		Comparator<EmployeeDetails2> empNameComparator2 = Comparator.comparing(EmployeeDetails2::getName).reversed();
			Collections.sort(eList, empNameComparator2);
Stream<T> peek(Consumer<? super T> action);		
	Stream.of("one", "two", "three", "four")
			.filter(e -> e.length() > 3)
				.peek(e -> System.out.println("Filtered value: " + e))
			.map(String::toUpperCase)
				.peek(e -> System.out.println("Mapped value: " + e))
				.collect(Collectors.toList());		
		This method mainly to support debugging, where you want to see the elements as they flow past a certain point in a pipeline.
		
		
Stream<T> limit(long maxSize);
		
Stream<T> skip(long n);
		
		
		
		
Optional<T> reduce(BinaryOperator<T> accumulator);
				Performs a reduction on the elements of this stream, using an associative accumulation function, 
					and returns an Optional describing the reduced value, if any.
        T   reduce(T identity, BinaryOperator<T> accumulator);
				Performs a reduction on the elements of this stream, using the provided identity value 
					and an associative accumulation function, and returns the reduced value.
      <U> U reduce(U identity,
                 BiFunction<U, ? super T, U> accumulator,
                 BinaryOperator<U> combiner);
				Performs a reduction on the elements of this stream, 
					using the provided identity accumulation and combining function
		Integer reduced = integers.stream().reduce(23, (a, b) -> a + b);
		numbers.stream().parallel()
				// .reduce(0, (x,y) -> x + y);
				//.reduce(0, Integer::sum);
				.reduce(0, MyClassA::sum);
		int greatest = numbers.stream().reduce(Integer.MIN_VALUE, (x, y) -> x > y ? x : y);






              

<R> R collect(Supplier<R> supplier,
                  BiConsumer<R, ? super T> accumulator,
                  BiConsumer<R, R> combiner)
                  	Performs a mutable reduction operation on the elements of this stream.
<R, A> R collect(Collector<? super T, A, R> collector)
	Performs a mutable reduction operation on the elements of this stream using a COllector 
	it is terminal operation
	List<String> resultList = list.stream().map(element -> element.toUpperCase()).collect(Collectors.toList());
	The reduction can also be provided by the collect() method of type Stream. 
	This operation is very handy in case of converting a stream to a Collection or a Map and representing a stream in form of a single string.
	There is a utility class Collectors which provide a solution for almost all typical collecting operations. 
	For some, not trivial tasks, a custom Collector can be created.

Object[] toArray();
<A> A[] toArray(IntFunction<A[]> generator);
	A[] men = getListA().stream().filter(p -> p.getAge() == 1).toArray(A[]::new);
	We can use toArray() method to copy elements present in the stream into specified array 
 		Integer[] ir = l1.stream().toArray(Integer[] :: new);  



Optional<T> min(Comparator<? super T> comparator);
Optional<T> max(Comparator<? super T> comparator);
	returns min/max value according to specified comparator
	
long count()
	count of elements in this stream
	it is terminal operation
	long count = list.stream().count();

boolean anyMatch(Predicate<? super T> predicate);
boolean allMatch(Predicate<? super T> predicate);
boolean noneMatch(Predicate<? super T> predicate);
	boolean isValid = list.stream().anyMatch(element -> element.contains("h")); // true
	boolean isValidOne = list.stream().allMatch(element -> element.contains("h")); // false
	boolean isValidTwo = list.stream().noneMatch(element -> element.contains("h")); // false
	
Optional<T> findFirst();
	Returns an Optional describing the first element of the stream  or an empty Optional if the stream is empty
Optional<T> findAny();
	Returns an Optional describing some element of the stream  or an empty Optional if the stream is empty


void forEach(Consumer<? super T> action);
void forEachOrdered(Consumer<? super T> action);
	In parallel programming element will print parallelly if we use forEach() method, so the order will not be fixed. 
	But in the use of forEachOrdered() fixed order in parallel streams
	
default Stream<T> takeWhile(Predicate<? super T> predicate) {}
	Stream.generate(()-> new Random().nextInt(100)).takeWhile(n-> n<=50);
default Stream<T> dropWhile(Predicate<? super T> predicate) {}

public static<T> Stream<T> empty() {}
public static<T> Stream<T> of(T t) {}
public static<T> Stream<T> ofNullable(T t) {}
public static<T> Stream<T> of(T... values) {   return Arrays.stream(values);}
public static<T> Builder<T> builder() {}
	
	
public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f) {}
	to create stream values on demand
	Return an infinite sequential ORDERED stream produced by iterative application of a function f of an initial element seed, 
		producing a stream consisting of seed, f(seed), f(f(seed))...etc
	It takes two parameters: an initial value, called seed element & a function which generates next element using the previous value
		Stream.iterate(1, n->n+1).limit(100);
	iterate() is stateful
public static<T> Stream<T> iterate(T seed, Predicate<? super T> hasNext, UnaryOperator<T> next) {}

public static<T> Stream<T> generate(Supplier<? extends T> s) {}
		Return an infinite sequential unordered stream where each element is generated by the provided supplier
		Stream.generate(()-> new Random().nextInt(100)).limit(100);
			generate() is not stateful
				diff value on each execution
		
public static <T> Stream<T> concat(Stream<? extends T> a, Stream<? extends T> b) {
	concatenation of the two input streams



